// app/robots.ts
import { MetadataRoute } from 'next'

const baseUrl = 'http://tikgrow.io/'

export default function robots(): MetadataRoute.Robots {
    return {
        rules: [
            {
                userAgent: '*',
                allow: [
                    '/',
                    '/vi/',
                    '/en/',
                    '/vi/tiktok-exchange-followers-likes',
                    '/en/tiktok-exchange-followers-likes',
                    '/vi/get-tiktok-followers-likes',
                    '/en/get-tiktok-followers-likes',
                    '/vi/campaigns',
                    '/en/campaigns',
                ],
                disallow: [
                    '/api/',
                ],
                // Crawl delay (tùy chọn - số giây delay giữa các request)
                crawlDelay: 1,
            },
            // Quy tắc riêng cho Google bot
            {
                userAgent: 'Googlebot',
                allow: [
                    '/',
                    '/vi/',
                    '/en/',
                ],
                disallow: [
                    '/api/',
                ],
            },
            // Quy tắc riêng cho Bing bot
            {
                userAgent: 'Bingbot',
                allow: [
                    '/',
                    '/vi/',
                    '/en/',
                ],
                disallow: [
                    '/api/',
                ],
            },
            // Block một số bot không mong muốn
            {
                userAgent: [
                ],
                disallow: '/',
            },
        ],
        sitemap: [
            `${baseUrl}/sitemap.xml`,
            // Nếu bạn có sitemap chunks
            `${baseUrl}/sitemap-static.xml`,
            `${baseUrl}/sitemap-campaigns.xml`,
            `${baseUrl}/sitemap-users.xml`,
        ],
        host: baseUrl,
    }
}

// Alternative: robots.txt với custom format
export function generateCustomRobots(): string {
    return `# Robots.txt for ${baseUrl}
# Generated by NextJS 15

# Allow all crawlers
User-agent: *
Allow: /
Allow: /vi/
Allow: /en/

# Specific pages to allow
Allow: /vi/tiktok-exchange-followers-likes
Allow: /en/tiktok-exchange-followers-likes
Allow: /vi/get-tiktok-followers-likes  
Allow: /en/get-tiktok-followers-likes
Allow: /vi/campaigns
Allow: /en/campaigns
Allow: /vi/profile
Allow: /en/profile

# Disallow sensitive areas
Disallow: /api/

# Crawl delay
Crawl-delay: 1

# Google specific rules
User-agent: Googlebot  
Allow: /
Allow: /vi/
Allow: /en/
Disallow: /api/

# Bing specific rules
User-agent: Bingbot
Allow: /
Allow: /vi/  
Allow: /en/
Disallow: /api/


# Sitemaps
Sitemap: ${baseUrl}/sitemap.xml
Sitemap: ${baseUrl}/sitemap-static.xml

# Host (optional)
Host: ${baseUrl}
`
}

// app/robots.txt/route.ts - Nếu muốn serve custom robots.txt
import { NextResponse } from 'next/server'

export async function GET() {
    const robotsContent = generateCustomRobots()

    return new NextResponse(robotsContent, {
        headers: {
            'Content-Type': 'text/plain',
            'Cache-Control': 'public, max-age=86400', // Cache 24 hours
        },
    })
}

// utils/robotsConfig.ts - Configuration file for robots rules
interface RobotsConfig {
    baseUrl: string
    allowedPaths: string[]
    disallowedPaths: string[]
    blockedUserAgents: string[]
    crawlDelay: number
    sitemaps: string[]
}

export const robotsConfig: RobotsConfig = {
    baseUrl: 'http://tikgrow.io/',
    allowedPaths: [
        '/',
        '/vi/',
        '/en/',
        '/vi/tiktok-exchange-followers-likes',
        '/en/tiktok-exchange-followers-likes',
        '/vi/get-tiktok-followers-likes',
        '/en/get-tiktok-followers-likes',
        '/vi/campaigns',
        '/en/campaigns',
        '/vi/profile',
        '/en/profile',
    ],
    disallowedPaths: [
        '/api/'
    ],
    blockedUserAgents: [
        // 'CCBot',
        // 'ChatGPT-User',
        // 'GPTBot',
        // 'Google-Extended',
        // 'anthropic-ai',
    ],
    crawlDelay: 1,
    sitemaps: [
        '/sitemap.xml',
        '/sitemap-static.xml'
    ]
}

// Dynamic robots generation based on environment
export function generateEnvironmentRobots(env: 'development' | 'staging' | 'production'): MetadataRoute.Robots {
    const config = robotsConfig

    if (env === 'development' || env === 'staging') {
        // Block all crawlers in non-production environments
        return {
            rules: {
                userAgent: '*',
                disallow: '/',
            },
            sitemap: `${config.baseUrl}/sitemap.xml`,
        }
    }

    // Production robots.txt
    return {
        rules: [
            {
                userAgent: '*',
                allow: config.allowedPaths,
                disallow: config.disallowedPaths,
                crawlDelay: config.crawlDelay,
            },
            {
                userAgent: 'Googlebot',
                allow: ['/', '/vi/', '/en/'],
                disallow: ['/api/'],
            },
            {
                userAgent: 'Bingbot',
                allow: ['/', '/vi/', '/en/'],
                disallow: ['/api/'],
            },
            ...config.blockedUserAgents.map(userAgent => ({
                userAgent,
                disallow: '/' as const,
            })),
        ],
        sitemap: config.sitemaps.map(sitemap => `${config.baseUrl}${sitemap}`),
        host: config.baseUrl,
    }
}